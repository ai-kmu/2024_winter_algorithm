{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import numpy as np\n",
        "import time\n",
        "from copy import deepcopy # Add Deepcopy for args\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import os\n",
        "import urllib.request\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "U_oR4TM_rSYq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "tedLiD3SpAHa",
        "outputId": "4a59ebdf-cfa5-44f9-ce86-ea51b9cf8a94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# CIFAR-100 데이터셋 다운로드\n",
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
        "filename = \"cifar-100-python.tar.gz\"\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# 압축 풀기\n",
        "os.system(\"tar xvzf \" + filename)\n",
        "\n",
        "# 데이터 불러오기\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "# 메타데이터 불러오기\n",
        "meta = unpickle('cifar-100-python/meta')\n",
        "fine_label_names = [t.decode('utf8') for t in meta[b'fine_label_names']]\n",
        "\n",
        "# 훈련 데이터 불러오기\n",
        "train = unpickle('cifar-100-python/train')\n",
        "\n",
        "# trainset : validationset = 8 : 2\n",
        "x_train, x_val, y_train, y_val = train_test_split(train[b'data'], train[b'fine_labels'], test_size=0.2, random_state=42)\n",
        "\n",
        "# 이미지 데이터 변환 함수\n",
        "# -> CIFAR 100의 데이터는 1차원으로 표현이 되기 때문에 plt를 통해 도식화 하려면 위와같이 channel, heigt, width (3차원)으로 바꾸고 다시 순서를 height, width ,channel로 바꾸어준다.\n",
        "def reshape_image(image):\n",
        "    return np.transpose(np.reshape(image,(3, 32,32)), (1,2,0))\n",
        "\n",
        "# 훈련 데이터의 첫 번째 이미지와 레이블 출력\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(reshape_image(x_train[0]))\n",
        "plt.title('Label: ' + fine_label_names[y_train[0]])\n",
        "plt.show()\n",
        "\n",
        "# 검증 데이터의 첫 번째 이미지와 레이블 출력\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(reshape_image(x_val[0]))\n",
        "plt.title('Label: ' + fine_label_names[y_val[0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# CIFAR-100 데이터를 PyTorch Dataset으로 변환하는 클래스\n",
        "class CIFAR100Dataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data.reshape(-1, 3, 32, 32).transpose((0, 2, 3, 1))  # 이미지 데이터를 (높이, 너비, 채널 수) 형태로 변환, 앞의 -1은 데이터의 갯수\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 이미지 데이터를 PyTorch tensor로 변환하고 정규화하는 변환 -> torch로 학습하기 위해 pytorch tensor로 변환\n",
        "# Tensor로 바꾸는 과정중에 0~255의 범위를 가지는 데이터를 RGB 채널 각각 0.5의 평균과 표준편차로 바꾸어줌\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 훈련 데이터와 검증 데이터를 PyTorch Dataset으로 변환\n",
        "trainset = CIFAR100Dataset(np.array(x_train), y_train, transform)\n",
        "valset = CIFAR100Dataset(np.array(x_val), y_val, transform)\n",
        "\n",
        "# 훈련 세션에 사용할 데이터 파티션\n",
        "partition = {'train': trainset, 'val': valset}"
      ],
      "metadata": {
        "id": "50_A3M0tpVcn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backborn model 지정\n",
        "# VGGnet기반 숫자는 filter size, M은 Max pooling\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "}"
      ],
      "metadata": {
        "id": "eGTrmP33sN-4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Architecture 지정\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, model_code, in_channels, out_dim, act, use_bn):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # activation function 설정\n",
        "        if act == 'relu':\n",
        "            self.act = nn.ReLU()\n",
        "        elif act == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        elif act == 'tanh':\n",
        "            self.act = nn.TanH()\n",
        "        else:\n",
        "            raise ValueError(\"Not a valid activation function code\")\n",
        "\n",
        "        # CNN 레이어들을 생성하는 함수 호출하여 레이어 생성\n",
        "        self.layers = self._make_layers(model_code, in_channels, use_bn)\n",
        "        # 과적합 방지를 위해 dropout설정하며 이를 classifier에 적용\n",
        "        self.dropout1 = nn.Dropout(0.7)\n",
        "        self.classifer = nn.Sequential(nn.Linear(512, 256),\n",
        "                                       self.act,\n",
        "                                       self.dropout1,\n",
        "                                       nn.Linear(256, out_dim))\n",
        "    # forward 연산 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)        # CNN 레이어들을 통과\n",
        "        x = x.view(x.size(0), -1) # Flatten 연산, 배치 크기는 유지하고 나머지 차원을 펼침\n",
        "        x = self.classifer(x)     # Classifier 통과\n",
        "        return x\n",
        "\n",
        "    # CNN 레이어들을 생성하는 함수\n",
        "    def _make_layers(self, model_code, in_channels, use_bn):\n",
        "        layers = []\n",
        "        for x in cfg[model_code]:\n",
        "            if x == 'M':\n",
        "                # MaxPooling 레이어 생성\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                # Convolution layer 구성\n",
        "                layers += [nn.Conv2d(in_channels=in_channels,\n",
        "                                     out_channels=x,  # out_channels은 forward 연산 이후 x\n",
        "                                     kernel_size=3,   # CNN kernel_size\n",
        "                                     stride=1,        # CNN kernel의 stride\n",
        "                                     padding=1)]      # CNN kernel의 padding\n",
        "\n",
        "                # BN(Batch Normalization을 사용하는 경우 아래를 사용)\n",
        "                if use_bn:\n",
        "                    layers += [nn.BatchNorm2d(x)]\n",
        "                layers += [self.act]   # 레이어 이후 활성화 함수 적용\n",
        "                in_channels = x        # 다음 들어가야하는 레이어에 입력 채널 수 업데이트\n",
        "\n",
        "        return nn.Sequential(*layers)  # 생성된 레이어들을 순차적으로 적용하여 모델을 정의(layer 리스트 내의 모든 레이어를 순차적으로 적용하여 하나의 시퀀스로 묶음)"
      ],
      "metadata": {
        "id": "7V-4zbErncCw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train session\n",
        "def train(net, partition, optimizer, criterion, args):\n",
        "    # trainset을 가져와서 batch_size, shuffle, num_workers(병렬적으로 데이터를 로드)\n",
        "    trainloader = torch.utils.data.DataLoader(partition['train'],\n",
        "                                              batch_size=args.train_batch_size,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "    net.train() # 학습모드 설정\n",
        "\n",
        "    correct = 0 # 맞은 예측 수\n",
        "    total = 0 # 전체 데이터 수\n",
        "    train_loss = 0.0 # train_loss\n",
        "    for i, data in enumerate(trainloader, 0): # 각 배치에 대해 반복\n",
        "        optimizer.zero_grad() # 옵티마이저 그래디언트 초기화 -> 다음 step으로 가기 위함\n",
        "\n",
        "        # input(입력 데이터, 레이블)\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda() # GPU 연산을 위해 GPU전송\n",
        "        labels = labels.cuda() # GPU 연산을 위해 GPU전송\n",
        "        outputs = net(inputs)  # network를 통과한 output값 (예측값)\n",
        "\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # backpropagaion\n",
        "        optimizer.step() # optimizer step\n",
        "\n",
        "        train_loss += loss.item() # loss를 추가\n",
        "        _, predicted = torch.max(outputs.data, 1) # output에서 가장 높은 확률값의 class 선택\n",
        "        total += labels.size(0) # 데이터 수 업데이트\n",
        "        correct += (predicted == labels).sum().item() # predict update(correct)\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)  # 평균 loss\n",
        "    train_acc = 100 * correct / total # accuracy\n",
        "    return net, train_loss, train_acc"
      ],
      "metadata": {
        "id": "bxSJ7HiSn4Hc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation seccison\n",
        "def validate(net, partition, criterion, args):\n",
        "    # validation set을 가져와서 batch_size, shuffle, num_workers(병렬적으로 데이터를 로드)\n",
        "    valloader = torch.utils.data.DataLoader(partition['val'],\n",
        "                                            batch_size=args.test_batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()  # 네트워크를 평가 모드 -> backprop을 안하기를 위한 목적도 있지만 Dropout이 적용될 경우 적용하지 않기 위함도 존재\n",
        "\n",
        "    correct = 0 # 맞은 예측 수\n",
        "    total = 0 # 전체 데이터 수\n",
        "    val_loss = 0 # validation_loss\n",
        "    with torch.no_grad(): # graident X\n",
        "        for data in valloader:  # 배치마다 data 반복\n",
        "            images, labels = data\n",
        "            images = images.cuda()  # GPU 연산을 위해 GPU전송\n",
        "            labels = labels.cuda()  # GPU 연산을 위해 GPU전송\n",
        "            outputs = net(images)   # network를 통과한 output값 (예측값)\n",
        "\n",
        "            loss = criterion(outputs, labels) # loss 계산\n",
        "\n",
        "            val_loss += loss.item() # loss를 추가\n",
        "            _, predicted = torch.max(outputs.data, 1) # output에서 가장 높은 확률값의 class 선택\n",
        "            total += labels.size(0) # 데이터 수 업데이트\n",
        "            correct += (predicted == labels).sum().item() # predict update(correct)\n",
        "\n",
        "        val_loss = val_loss / len(valloader)  # 평균 loss\n",
        "        val_acc = 100 * correct / total # accuracy\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "3YX6Pz_Sn4os"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment(partition, args):\n",
        "\n",
        "    # CNN model 지정\n",
        "    net = CNN(model_code = args.model_code,\n",
        "              in_channels = args.in_channels,\n",
        "              out_dim = args.out_dim,\n",
        "              act = args.act,\n",
        "              use_bn = args.use_bn\n",
        "              )\n",
        "    # GPU 연산을 위해 cuda로\n",
        "    net.cuda()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() # loss 계산(class 분류)을 위한 Loss계산법 정의\n",
        "    if args.optim == 'SGD': # SGD를 사용할 때\n",
        "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop': # RMSProp를 사용할 때\n",
        "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':  # Adam를 사용할 때\n",
        "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice') # 위의 optim을 사용하지 않았을때 Error송출\n",
        "\n",
        "    # 각 loss, acc에 대해 저장할 리스트 생성\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "\n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()  # 학습시간을 계산하기 위해 초기 시간 기록\n",
        "        net, train_loss, train_acc = train(net, partition, optimizer, criterion, args) # 위에서 정의 한 train function 호출\n",
        "        val_loss, val_acc = validate(net, partition, criterion, args) # 위에서 정의한 validation\n",
        "        te = time.time() # 종료 시간 -> 한번 학습이 돌아갔을때의 시간 (te - ts -> 학습시간)\n",
        "\n",
        "        # 각 loss를 저장함\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # 한 epoch당 acc, loss를 뱉어줌\n",
        "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "\n",
        "        # 매 에폭이 끝날 때마다 모델의 가중치를 저장\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            weight_save_path = f\"saved_weights_epoch_{epoch + 1}.pth\"  # 에폭에 따른 파일명 생성\n",
        "            torch.save(net.state_dict(), weight_save_path)\n",
        "\n",
        "    # 결과를 result에 따로 저장함\n",
        "    result = {}\n",
        "    result['train_losses'] = train_losses\n",
        "    result['val_losses'] = val_losses\n",
        "    result['train_accs'] = train_accs\n",
        "    result['val_accs'] = val_accs\n",
        "    result['train_acc'] = train_acc\n",
        "    result['val_acc'] = val_acc\n",
        "    return vars(args), result"
      ],
      "metadata": {
        "id": "wpl8Votsn6fo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import json\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "def save_exp_result(setting, result):\n",
        "    exp_name = setting['exp_name']  # exp_name을 가져옴\n",
        "    del setting['epoch']  # epoch key delete\n",
        "    del setting['test_batch_size']  # test_batch delete\n",
        "\n",
        "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]  # 설정을 해싱\n",
        "    filename = './results/{}-{}.json'.format(exp_name, hash_key)  # 결과를 저장할 파일 경로 지정\n",
        "    result.update(setting)  # 설정을 result에 update\n",
        "    with open(filename, 'w') as f:  # exp_name, hash_key를 가지는 파일 이름으로 저장\n",
        "        json.dump(result, f)"
      ],
      "metadata": {
        "id": "Sd1-sjPfoABU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Random Seed Initialization ====== #\n",
        "# 동일한 코드를 여러번 실행할 때 동일한 결과를 얻을 수 있는데 이를 방지하기 위함\n",
        "seed = 123\n",
        "np.random.seed(seed)  # numpy random seed\n",
        "torch.manual_seed(seed) # torch random seed\n",
        "\n",
        "parser = argparse.ArgumentParser()  # 명령행 옵션을 파싱\n",
        "args = parser.parse_args(\"\")  # 파싱 이후 결과 저장\n",
        "args.exp_name = \"exp1_lr_model_code\"  # exp_name 저장\n",
        "\n",
        "# ====== Model ====== #\n",
        "args.model_code = 'VGG11'\n",
        "args.in_channels = 3  # input channel\n",
        "args.out_dim = 100   # output channel\n",
        "args.act = 'relu'   # activation function\n",
        "\n",
        "# ====== Regularization ======= #\n",
        "args.l2 = 0.01   # L2 Norm\n",
        "args.use_bn = True  # Batch Normalization\n",
        "\n",
        "# ====== Optimizer & Training ====== #\n",
        "args.optim = 'Adam' #'RMSprop' #SGD, RMSprop, ADAM...\n",
        "args.lr = 0.00005  # learning rate\n",
        "args.epoch = 100   # epoch\n",
        "\n",
        "args.train_batch_size = 512 # train_batch_size\n",
        "args.test_batch_size = 1024 # test_batch_size\n",
        "\n",
        "setting, result = experiment(partition, args)\n",
        "save_exp_result(setting, result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PdwHqG1OoDiX",
        "outputId": "a60880a7-0134-410f-c0f6-11c9cf8f12b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Acc(train/val): 3.73/11.38, Loss(train/val) 4.48/4.26. Took 10.28 sec\n",
            "Epoch 1, Acc(train/val): 8.45/15.80, Loss(train/val) 4.20/3.91. Took 10.41 sec\n",
            "Epoch 2, Acc(train/val): 12.77/20.82, Loss(train/val) 3.94/3.66. Took 10.14 sec\n",
            "Epoch 3, Acc(train/val): 16.32/24.66, Loss(train/val) 3.71/3.45. Took 10.23 sec\n",
            "Epoch 4, Acc(train/val): 20.43/27.75, Loss(train/val) 3.47/3.24. Took 11.08 sec\n",
            "Epoch 5, Acc(train/val): 24.35/30.15, Loss(train/val) 3.25/3.09. Took 10.38 sec\n",
            "Epoch 6, Acc(train/val): 28.68/32.12, Loss(train/val) 3.02/2.96. Took 10.47 sec\n",
            "Epoch 7, Acc(train/val): 32.89/34.25, Loss(train/val) 2.81/2.81. Took 9.95 sec\n",
            "Epoch 8, Acc(train/val): 37.93/35.85, Loss(train/val) 2.57/2.74. Took 10.07 sec\n",
            "Epoch 9, Acc(train/val): 42.93/36.56, Loss(train/val) 2.33/2.70. Took 10.13 sec\n",
            "Epoch 10, Acc(train/val): 48.80/36.23, Loss(train/val) 2.08/2.67. Took 10.20 sec\n",
            "Epoch 11, Acc(train/val): 55.01/36.94, Loss(train/val) 1.81/2.62. Took 10.42 sec\n",
            "Epoch 12, Acc(train/val): 61.71/35.98, Loss(train/val) 1.55/2.65. Took 9.95 sec\n",
            "Epoch 13, Acc(train/val): 67.90/36.57, Loss(train/val) 1.32/2.59. Took 10.16 sec\n",
            "Epoch 14, Acc(train/val): 74.42/35.94, Loss(train/val) 1.08/2.67. Took 10.03 sec\n",
            "Epoch 15, Acc(train/val): 79.98/35.92, Loss(train/val) 0.89/2.62. Took 10.03 sec\n",
            "Epoch 16, Acc(train/val): 85.06/36.53, Loss(train/val) 0.71/2.67. Took 10.55 sec\n",
            "Epoch 17, Acc(train/val): 88.58/36.55, Loss(train/val) 0.59/2.67. Took 9.79 sec\n",
            "Epoch 18, Acc(train/val): 92.14/36.14, Loss(train/val) 0.47/2.70. Took 10.10 sec\n",
            "Epoch 19, Acc(train/val): 94.15/36.01, Loss(train/val) 0.38/2.72. Took 10.17 sec\n",
            "Epoch 20, Acc(train/val): 95.67/36.73, Loss(train/val) 0.32/2.66. Took 10.08 sec\n",
            "Epoch 21, Acc(train/val): 96.95/36.48, Loss(train/val) 0.26/2.67. Took 12.31 sec\n",
            "Epoch 22, Acc(train/val): 97.75/36.87, Loss(train/val) 0.22/2.70. Took 10.19 sec\n",
            "Epoch 23, Acc(train/val): 98.22/36.03, Loss(train/val) 0.20/2.80. Took 10.03 sec\n",
            "Epoch 24, Acc(train/val): 98.50/37.04, Loss(train/val) 0.18/2.68. Took 10.18 sec\n",
            "Epoch 25, Acc(train/val): 98.75/36.69, Loss(train/val) 0.16/2.73. Took 10.13 sec\n",
            "Epoch 26, Acc(train/val): 98.92/36.91, Loss(train/val) 0.15/2.73. Took 10.36 sec\n",
            "Epoch 27, Acc(train/val): 99.23/37.61, Loss(train/val) 0.14/2.70. Took 10.02 sec\n",
            "Epoch 28, Acc(train/val): 99.17/37.12, Loss(train/val) 0.13/2.72. Took 10.09 sec\n",
            "Epoch 29, Acc(train/val): 99.32/36.37, Loss(train/val) 0.12/2.72. Took 10.90 sec\n",
            "Epoch 30, Acc(train/val): 99.47/36.49, Loss(train/val) 0.12/2.74. Took 11.89 sec\n",
            "Epoch 31, Acc(train/val): 99.47/36.17, Loss(train/val) 0.12/2.78. Took 11.87 sec\n",
            "Epoch 32, Acc(train/val): 99.41/36.40, Loss(train/val) 0.12/2.76. Took 11.48 sec\n",
            "Epoch 33, Acc(train/val): 99.38/35.41, Loss(train/val) 0.12/2.88. Took 11.47 sec\n",
            "Epoch 34, Acc(train/val): 99.16/36.41, Loss(train/val) 0.13/2.78. Took 11.90 sec\n",
            "Epoch 35, Acc(train/val): 99.58/36.51, Loss(train/val) 0.10/2.80. Took 9.91 sec\n",
            "Epoch 36, Acc(train/val): 99.62/36.40, Loss(train/val) 0.10/2.75. Took 10.16 sec\n",
            "Epoch 37, Acc(train/val): 99.73/35.94, Loss(train/val) 0.09/2.78. Took 10.18 sec\n",
            "Epoch 38, Acc(train/val): 99.30/36.05, Loss(train/val) 0.12/2.81. Took 10.11 sec\n",
            "Epoch 39, Acc(train/val): 99.54/36.31, Loss(train/val) 0.11/2.79. Took 11.65 sec\n",
            "Epoch 40, Acc(train/val): 99.56/36.20, Loss(train/val) 0.11/2.78. Took 10.60 sec\n",
            "Epoch 41, Acc(train/val): 99.73/35.69, Loss(train/val) 0.09/2.81. Took 10.36 sec\n",
            "Epoch 42, Acc(train/val): 99.45/33.75, Loss(train/val) 0.11/2.96. Took 10.44 sec\n",
            "Epoch 43, Acc(train/val): 99.68/34.43, Loss(train/val) 0.10/2.91. Took 10.49 sec\n",
            "Epoch 44, Acc(train/val): 99.54/35.18, Loss(train/val) 0.11/2.87. Took 12.17 sec\n",
            "Epoch 45, Acc(train/val): 99.60/32.68, Loss(train/val) 0.11/3.02. Took 10.83 sec\n",
            "Epoch 46, Acc(train/val): 99.53/35.61, Loss(train/val) 0.11/2.84. Took 10.40 sec\n",
            "Epoch 47, Acc(train/val): 99.61/33.82, Loss(train/val) 0.11/2.96. Took 9.96 sec\n",
            "Epoch 48, Acc(train/val): 99.64/33.71, Loss(train/val) 0.10/3.00. Took 10.13 sec\n",
            "Epoch 49, Acc(train/val): 98.97/33.61, Loss(train/val) 0.15/2.97. Took 10.12 sec\n",
            "Epoch 50, Acc(train/val): 99.13/33.38, Loss(train/val) 0.14/2.98. Took 10.07 sec\n",
            "Epoch 51, Acc(train/val): 99.20/34.11, Loss(train/val) 0.14/2.96. Took 10.40 sec\n",
            "Epoch 52, Acc(train/val): 99.37/33.54, Loss(train/val) 0.11/3.02. Took 10.04 sec\n",
            "Epoch 53, Acc(train/val): 99.39/36.09, Loss(train/val) 0.12/2.84. Took 10.06 sec\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-51122b36d57b>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;31m# test_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0msave_exp_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-314d9cf63d85>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(partition, args)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 학습시간을 계산하기 위해 초기 시간 기록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 위에서 정의 한 train function 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 위에서 정의한 validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 종료 시간 -> 한번 학습이 돌아갔을때의 시간 (te - ts -> 학습시간)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-9ac39cee1823>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, partition, optimizer, criterion, args)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss를 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output에서 가장 높은 확률값의 class 선택\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 데이터 수 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}